# Chapter 7: Thinking, Control and Intelligence

What is *smart*?  This is the fundamental question for this chapter, with many profound personal and societal implications.  Is there just one kind of smart, or are there multiple different forms of intelligence?  How can we reconcile any form of *general* intelligence with everything we've learned up to this point, about how the brain works at a biological level?  The brain is composed of billions of neurons, interconnected by vast networks of synapses, wherein all of our knowledge, and, presumably, intelligence, must lie.  Do "smart" people have more neurons or synapses?  Or, perhaps, *fewer* synapses?  Are their neurons somehow fundamentally different from other people who measure as less smart according to standard intelligence tests?  And what are those intelligence tests measuring anyway?  Are they really some kind of "pure" measure of intelligence, or do they just reflect the degree of western-style education (and health and wealth) that a person has?  What does your IQ score really tell us about you as a thinker, and about your prospects for future success in school and the real world?  So many important questions!

If our brains were more like digital computers, these questions would have much simpler answers.  It is relatively easy to measure the power and speed of a computer, and many people tend to think of human intelligence in these terms.  As we discussed in the previous chapter, a computer has discrete parts (the CPU, RAM, and hard drive), and each of these parts can be directly quantified in terms of its capacity and speed.  If you're at all savvy about these things, you can obsess about getting the best value for your money along each of these dimensions, and, generally speaking, the faster the CPU and the more RAM and hard-drive storage, the more you can achieve with your computer.  Computers really do come in obvious degrees of "smartness".

But our brains are nothing like that of a digital computer.  We do *not* have a CPU (at least, not one like that in a standard computer -- more on this in a moment).  Cognition emerges out of the interactions of billions of chattering neurons, which are fundamentally shaped by learning processes over an extended period of time.  As we will explore in the development chapter, we start out with virtually no discernible intelligence (despite how cute and special our parents think we are), and it takes most people a few *years* to even learn how to control their own bowels!  Wow.  The rest of the animal kingdom must think we are complete idiots, which comports with an amusing *Onion* headline to that effect.

Given that we clearly don't start out with much in the way of intelligence, it seems hard to escape the conclusion that intelligence is fundamentally a product of learning (in concert with other developmental / maturational changes).  And this view is also hard to avoid when you think about all those synapses that need to get wired up in just the right way to produce whatever cognitive abilities we end up with.

So are "smart" people just better learners then?  If so, what makes some people better at learning than others?  When we explored this question in the Learning chapter, one of the major conclusions is that learning is driven fundamentally by *motivation*, and all that dopamine and related machinery that gets us up in the morning and ready to pursue our daily goals, etc.

Indeed, we will review various sources of evidence that are consistent with the overall idea that motivational differences play an outsized role in determining measured level of intelligence.  Of course, there are many, many complex factors that shape an individual's trajectory of learning and development, and motivation is itself a multi-faceted thing, so perhaps we aren't explaining too much when we say that motivation plays an important role.

But understanding the major factors shaping intelligence may affect how we think about ourselves, and others, in important ways.  If we view intelligence as a product of learning and motivation, then it is more obviously something malleable.  This is the critical difference between a **fixed mindset** about intelligence, versus a **growth mindset**, as emphasized by *Carol Dweck* and colleagues [@Dweck08], in an increasingly influential body of work.  The growth mindset emphasizes that intelligence is not something that people "have", but rather, something they have to cultivate -- something that grows over time.  Increasingly, schools and teachers are recognizing that motivational factors have a huge impact on educational success, and they are developing innovative ways of motivating students to learn, and making the material more obviously self-relevant.

Fundamentally, the idea that intelligence is largely the product of time spent learning means that **anyone can learn anything**, if they only have sufficient motivation and time to invest into it.  This open-ended, ambitious view of intelligence surely has the effect of opening up your individual horizons and sense of what is possible.  Personally, I have always had this belief, and I have learned lots of complicated things, often slowly and with great difficulty.  But eventually, things that once seemed impenetrable become just another familiar part of my mental toolkit.  I have a very salient early memory of spending much longer than my peers figuring out how to simply connect a battery to some gadget in a summer school class as a kid.  I felt like an idiot.  But eventually, I figured it out, and learned this valuable lesson that, with sufficient effort, I could succeed.

Hopefully, you are now motivated to learn more about the history and current state of understanding about the nature of human intelligence, and the thinking processes that underlie it!  We'll start off by exploring the core questions of what "thinking" is, and what kinds of brain mechanisms are particularly important for it.  The conclusion from this may seem to contradict what was just said above: maybe we *do* have something like a CPU in our heads after all -- except it is a CPU made out of neurons and brain systems, and it runs on dopamine!  This is an important example of an *emergent* system, like the gears we talked about in the neuroscience chapter: the overall function of a CPU can be supported by various different "substances", just like the gears can be made of many different materials, and yet still function more-or-less the same.

Nevertheless, our neural CPU has major differences from a computer CPU, and the fact that it is made of neurons does have important implications for how it works.  Indeed, one can understand a lot about the particular strengths and limitations of human cognitive function, in terms of the overall idea that we can do both neuron-like computation, *and* something that approximates the function of a digital CPU.  We have yet to develop powerful AI (artificial intelligence) systems that capture this unique combination of both forms of computation, and perhaps once we do, we will unlock the real magic of our brains!

After gaining a better understanding of the "mechanics" of intelligence, we'll review the history of thought about the nature of intelligence, and how it has been measured.  Furthermore, we'll examine the data about the real-world implications of IQ test scores, and circle back to these big questions about the relationship between intelligence and motivation.

Another way of thinking about all of these issues, is in terms of the *control* component of our three-C's.  Our neural CPU serves as a kind of overall control system for the rest of our brain, and, as we have emphasized, this is fundamentally a *motivated* form of control, focused on getting us the things we need and want, and avoiding all the bad stuff.  Thus, the idea that motivation and intelligence are inextricably intertwined makes perfect sense from this perspective: the brain systems supporting our control systems (in the prefrontal cortex and basal ganglia) are the very same ones that directly interface with lower-level motivational and emotional pathways in the amygdala and dopamine system.

## The Neural CPU in the Prefrontal Cortex and Basal Ganglia

If we are to have something like a computer CPU in our brains, we can use what we know about how such a thing works to provide a specification for the kinds of properties this system must have.  At the most abstract level, *Alan Turing* and *John Von Neumann* worked out the basic principles of a *universal* computational device in the 1930's and 40's [@Turing36; @vonNeumann45] -- something that could in principle do *anything*.  Amazingly, this device is remarkably simple.  It only requires a way of reading and writing information from a memory system (conceptualized as a *tape* by Turing), and a program that determines how this information is transformed in between being read and written.  It also requires some *active* memory where things can be temporarily cached, for the program to refer to.  These elements were elaborated by Von Neumann, in one of the most important unpublished papers of all time [@vonNeumann45], creating the foundation for modern digital computers.

An essential element of universal computation is its *serial* nature -- the computation unfolds one discrete step at a time, and significant power is obtained by being able to arbitrarily recombine different elements of these sequential steps, to construct arbitrary sequences of ... anything!  By contrast, parallel systems have many more constraints, and are *not* generally universal computational systems.  One major reason is because of potentially arbitrary interdependencies among different parts of the overall problem being worked on.  If you're computing  basic multi-digit addition, you can't just add up all the individual digits you see in parallel -- you need to keep the ones column separate from the tens column, etc, and carry the proper extra digits over, etc.  This is easily achieved in a sequential program, where the active memory is used to hold on to the current carry digit and also what place you're currently at.  You can hopefully picture yourself executing each of these sequential steps as you learned them in elementary school -- that is really the essence of how a Turing machine works.

And you just can't achieve the same kind of mathematical power using a fully parallel system, like the way that your neurons work.  Specific instances of multi-digit addition problems can be solved by specific configurations of parallel neural-like systems, but it is very difficult to come up with a truly general purpose such parallel system.  Thus, we are left with this rather startling conclusion: our super huge brains packed with neurons are in many ways no match for a simple serial computational device composed of just a few basic parts.  Indeed, growing up in the era when cheap digital calculators first became widely available, it became very clear that while our brains are impressive in some ways, they pale in comparison to a dime-store calculator for doing basic arithmetic!

From this perspective, it is perhaps then not too surprising that our brains have evolved at least some elements of this serial, universal computational capacity.  Specifically, we can use oure *natural language* as a kind of programming language, together with our ability to maintain a small amount of information in active, **working memory**, to string together a sequence of mental operations, in order to solve novel, challenging tasks.  For example, wWhen you solve a mental arithmetic problem, you are constantly juggling the digits around in your working memory, and using some kind of verbal self-instruction to remind yourself of what steps to perform next.  And more generally, you're likely to find yourself using this same kind of effortful, sequential mental juggling act for any kind of novel, challenging task.  For example, when you first learn to drive a car, you rely on this same kind of slow, deliberate process that consumes all of your attention, as you keep reminding yourself of what you are supposed to be doing at each point in time.

Over time, with sufficient practice, these slow effortful processes gradually become **automated**, and you may now find yourself driving down the freeway with very little awareness of any of the underlying steps you're effortlessly performing.  This difference between the initial effortful __controlled processing__ and the subsequent __automatic processing__ was captured in a highly influential pair of papers by *Walter Schneider* and *Richard Shiffrin* (the same one who published the famous paper on the modal model of memory from the previous chapter) [@SchneiderShiffrin77; @ShiffrinSchneider77].

* Baddeley working memory

* PFC

* active maintenance

* "juggling" of information and bg "gating"

* Turing machines and CPU's: The inherent flexibility of sequential processing: universal computation

* Controlled vs. automatic processing, stroop task


## Differences between Computers and our Neural CPU's

* computers can do prodigious amounts of math & statistics, very quickly

* we kinda suck at that stuff

* but we have neurons!!  those neurons can use *parallel* pattern recognition kinds of strategies to solve problems in a "pragmatic" way..

* heuristics and biases..


## Measuring Intelligence and its Implications

* IQ tests

* Multiple intelligences

* real-world implications

* Dweck etc 

* Vogel WM study

* Miyake & Friedman and the genetic basis of IQ: gets stronger over time, just like a learning system.

* important considerations in interpreting genetic results..




